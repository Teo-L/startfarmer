{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k최근접이웃_교차검증(by 이미희)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   외부 일사량  내부온도  내부습도  내부CO2\n",
      "0   223.0  17.0  58.0  500.0\n",
      "1   114.0  12.0  74.0  586.0\n",
      "2   140.0  10.0  83.0  557.0\n",
      "3   177.0  10.0  84.0  525.0\n",
      "4    64.0  10.0  84.0  565.0\n",
      "훈련 점수 : 0.9205, 테스트 점수 : 0.8925 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#데이터 로드\n",
    "crops = pd.read_csv('./data/dataset.csv', thousands=',')\n",
    "\n",
    "# 품종별 Label 붙이기\n",
    "def result(row):\n",
    "    if row[0] == '딸기':\n",
    "        return 0\n",
    "    elif row[0] == '토마토':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "crops['Label'] = crops.apply(result,axis=1)\n",
    "\n",
    "# Label 종류별 갯수확인\n",
    "crops['Label'].value_counts()\n",
    "\n",
    "# 결측치 확인\n",
    "crops.isnull().sum()\n",
    "\n",
    "# 결측치 행 삭제 및 확인\n",
    "crops1 = crops.dropna(axis=0)\n",
    "crops1.isnull().sum()\n",
    "\n",
    "crops1_input = crops1[['외부 일사량','내부온도','내부습도','내부CO2']]\n",
    "print(crops1_input[:5])\n",
    "\n",
    "crops1_target = crops1['Label']\n",
    "\n",
    "train_input,test_input,train_target,test_target = train_test_split(crops1_input, crops1_target,test_size=0.2)\n",
    "\n",
    "# StandardScaler(표준화)로 데이터 셋 변환\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.fit_transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "#모델 학습\n",
    "kn = KNeighborsClassifier(n_neighbors=5)\n",
    "kn.fit(train_scaled, train_target)\n",
    "train_score = kn.score(train_scaled, train_target)\n",
    "test_score = kn.score(test_scaled, test_target)\n",
    "print(f'훈련 점수 : {train_score :.4f}, 테스트 점수 : {test_score :.4f} ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(\n",
    "    estimator = KNeighborsClassifier(),\n",
    "    X=crops1_input, y=crops1_target,\n",
    "    cv=5,\n",
    "    n_jobs=multiprocessing.cpu_count(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 하기\n",
    "param_grid = [{'n_neighbors': [3,5,7],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'algorithm': ['ball_tree','kd_tree', 'brute']}]\n",
    "\n",
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=multiprocessing.cpu_count(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "gs.fit(crops1_input, crops1_target)\n",
    "\n",
    "# 최적의 결과\n",
    "print(gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화- 함수 만들기\n",
    "def make_meshgrid(x,y,h=.02):\n",
    "    x_min, x_max = x.min()-1, x.max()+1\n",
    "    y_min, y_max = y.min()-1, y.max()+1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                            np.arange(y_min, y_max, h))\n",
    "\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(clf, xx, yy, **parrams):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(x.shape)\n",
    "    out = plt.contourf(xx,yy,Z,**params)\n",
    "\n",
    "    return out\n",
    "\n",
    "# 시각화(TSNE:저차원..?)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)  #밑에 df에서 2개의 feature로 나옴\n",
    "X_comp = tsne.fit_transform(crops1_input)\n",
    "\n",
    "crops1_comp_df = pd.DataFrame(data=X_comp)\n",
    "crops1_comp_df['Label'] = crops1_target\n",
    "crops1_comp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn-whitegrid'])\n",
    "\n",
    "plt.scatter(X_comp[:,0], X_comp[:,1],\n",
    "            c=crops1_target, cmap=plt.cm.coolwarm, s=20, edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱_다중분류(by 추동헌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 점수 : 0.9069, 테스트 점수 : 0.8999 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import softmax\n",
    "\n",
    "grass = pd.read_csv('./data/dataset.csv',thousands=',')\n",
    "\n",
    "# 결측치 확인\n",
    "grass.isnull().sum()\n",
    "\n",
    "#결측치 제거\n",
    "grass.dropna(axis=0,inplace=True)\n",
    "\n",
    "grass_input= grass[['외부 일사량','내부온도','내부습도','내부CO2','지습']].to_numpy()\n",
    "\n",
    "grass_target = grass['품목명'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(grass_input,grass_target,random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "lr = LogisticRegression(C=20, max_iter=1000)\n",
    "lr.fit(train_scaled, train_target)\n",
    "train_score = lr.score(train_scaled, train_target)\n",
    "test_score = lr.score(test_scaled, test_target)\n",
    "print(f'훈련 점수 : {train_score :.4f}, 테스트 점수 : {test_score :.4f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 포레스트(by 정서현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "veggie = pd.read_csv('./data/dataset.csv', thousands= ',')\n",
    "veggie.head()\n",
    "\n",
    "veggie.dropna(inplace=True)\n",
    "\n",
    "data = veggie[['외부 일사량', '내부온도', '내부습도' ,'내부CO2','지습']].to_numpy()\n",
    "target = veggie['품목명'].to_numpy()\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
    "\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 결과값 : 외부 일사량, 내부온도, 내부습도, 내부co2,지습 순서대로 중요도\n",
    "- => 지습의 중요도가 가장 높다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤포레스트에서 자체적으로 모델을 평가하는 점수\n",
    "# oob(Out Of Bag) 샘플을 활용하여 부트스트랩 샘플로 훈련한 결정 트리를 평가할 수 있음.\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정 트리(by 이태호)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정트리 정확도 :  0.9732\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#데이터 로드\n",
    "farmdata = pd.read_csv('./data/dataset.csv', thousands=',')\n",
    "\n",
    "#결측치 제거\n",
    "farmdata.dropna(inplace=True)\n",
    "\n",
    "#데이터 분할\n",
    "data = farmdata[['외부 일사량', '내부온도', '내부습도', '내부CO2', '지습']].to_numpy()\n",
    "target = farmdata['품목명'].to_numpy()\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# DecisionTree Classifier 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156,min_samples_leaf=4,max_depth=7)\n",
    "\n",
    "# DecisionTreeClassifer 학습. \n",
    "dt_clf.fit(train_input , train_target)\n",
    "\n",
    "#예측하기\n",
    "pred = dt_clf.predict(test_input)\n",
    "\n",
    "#평가하기\n",
    "print(f'결정트리 정확도 : {accuracy_score(test_target,pred): .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보팅(Voting)-KNN+DecisionTree(by 이태호)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m vo_clf \u001b[39m=\u001b[39m VotingClassifier( estimators\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mLR\u001b[39m\u001b[39m'\u001b[39m,lr_clf),(\u001b[39m'\u001b[39m\u001b[39mKNN\u001b[39m\u001b[39m'\u001b[39m,knn_clf),(\u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m,svc_clf)] , voting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoft\u001b[39m\u001b[39m'\u001b[39m ) \n\u001b[0;32m     31\u001b[0m \u001b[39m#소프트 보팅방식\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# VotingClassifier 학습/예측/평가. \u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m vo_clf\u001b[39m.\u001b[39;49mfit(train_input , train_target)\n\u001b[0;32m     35\u001b[0m pred \u001b[39m=\u001b[39m vo_clf\u001b[39m.\u001b[39mpredict(test_input)\n\u001b[0;32m     36\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mVoting 분류기 정확도: \u001b[39m\u001b[39m{0:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(accuracy_score(test_target , pred)))\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:351\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m    349\u001b[0m transformed_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mtransform(y)\n\u001b[1;32m--> 351\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, transformed_y, sample_weight)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:83\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators):\n\u001b[0;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     79\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\u001b[39m}\u001b[39;00m\u001b[39m weights, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators)\u001b[39m}\u001b[39;00m\u001b[39m estimators\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m     84\u001b[0m     delayed(_fit_single_estimator)(\n\u001b[0;32m     85\u001b[0m         clone(clf),\n\u001b[0;32m     86\u001b[0m         X,\n\u001b[0;32m     87\u001b[0m         y,\n\u001b[0;32m     88\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m     89\u001b[0m         message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mVoting\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     90\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(names[idx], idx \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(clfs)),\n\u001b[0;32m     91\u001b[0m     )\n\u001b[0;32m     92\u001b[0m     \u001b[39mfor\u001b[39;49;00m idx, clf \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(clfs)\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;49;00m clf \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     94\u001b[0m )\n\u001b[0;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_estimators_ \u001b[39m=\u001b[39m Bunch()\n\u001b[0;32m     98\u001b[0m \u001b[39m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:47\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m---> 47\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:251\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 251\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    252\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:333\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    319\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    321\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    323\u001b[0m (\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[1;32m--> 333\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    334\u001b[0m     X,\n\u001b[0;32m    335\u001b[0m     y,\n\u001b[0;32m    336\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    337\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    338\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_,\n\u001b[0;32m    339\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    340\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    341\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    342\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    343\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    344\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    345\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    346\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    347\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    348\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    349\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    350\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    351\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    352\u001b[0m )\n\u001b[0;32m    354\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#데이터 로드\n",
    "farmdata = pd.read_csv('./data/dataset.csv', thousands=',')\n",
    "\n",
    "#결측치 제거\n",
    "farmdata.dropna(inplace=True)\n",
    "\n",
    "#데이터 분할\n",
    "data = farmdata[['외부 일사량', '내부온도', '내부습도', '내부CO2', '지습']].to_numpy()\n",
    "target = farmdata['품목명'].to_numpy()\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "#모델 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156,min_samples_leaf=6,max_depth=4)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "svc_clf = SVC(probability=True,kernel='linear')\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('DT',dt_clf),('KNN',knn_clf),('SVC',svc_clf)] , voting='soft' ) \n",
    "#소프트 보팅방식\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(train_input , train_target)\n",
    "pred = vo_clf.predict(test_input)\n",
    "print('Voting 정확도: {0:.4f}'.format(accuracy_score(test_target , pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 모델의 실행속도가 느려 적합하지 않다고 판단."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost(by 이태호)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 설치\n",
    "!pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb #파이썬 wrapper 클래스\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#데이터 로드\n",
    "farmdata = pd.read_csv('./data/dataset.csv', thousands=',')\n",
    "\n",
    "#결측치 제거\n",
    "farmdata.dropna(inplace=True)\n",
    "\n",
    "plants = ['딸기', '토마토', '파프리카']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후 , fit( ) 과 transform( ) 으로 label 인코딩 수행. \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(plants)\n",
    "labels = encoder.transform(plants)\n",
    "label_farmdata = farmdata.apply(LabelEncoder().fit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 분할\n",
    "data = label_farmdata[['외부 일사량', '내부온도', '내부습도', '내부CO2', '지습']].to_numpy()\n",
    "target = label_farmdata['품목명'].to_numpy()\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train_input , label=train_target)\n",
    "dtest = xgb.DMatrix(data=test_input , label=test_target)\n",
    "\n",
    "# 모델 튜닝\n",
    "params = { 'max_depth':3, #트리깊이\n",
    "           'eta': 0.1, #학습률\n",
    "           'objective':'multi:softmax', #다중분류\n",
    "           'num_class':3,\n",
    "           'eval_metric':'merror', #평가지표\n",
    "        }\n",
    "num_rounds = 400\n",
    "\n",
    "# train 데이터 셋은 ‘train’ , evaluation(test) 데이터 셋은 ‘eval’ 로 명기\n",
    "wlist = [(dtrain,'train'),(dtest,'eval') ]\n",
    "\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달\n",
    "xgb_model = xgb.train(params = params , dtrain=dtrain , num_boost_round=num_rounds , early_stopping_rounds=100, evals=wlist )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict을 통해 수행한 결과값 중 10개만 표시, 예측 확률 값으로 표시됨\n",
      "[2. 1. 0. 2. 1. 2. 0. 2. 0. 2.]\n",
      "예측값 10개만 표시: [1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict을 통해 수행한 결과값 중 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장 \n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "\n",
    "print('예측값 10개만 표시:',preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(test_target, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( test_target, pred)\n",
    "    accuracy = accuracy_score(test_target , pred)\n",
    "    precision = precision_score(test_target , pred, average='micro')\n",
    "    recall = recall_score(test_target , pred, average='micro')\n",
    "    f1 = f1_score(test_target,pred, average='micro')\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}'.format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[ 751    6    0]\n",
      " [  13  660    0]\n",
      " [   0 1296    0]]\n",
      "정확도: 0.5176, 정밀도: 0.5176, 재현율: 0.5176,    F1: 0.5176\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(test_target , preds, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 예제에서 학습한 내용을 바탕으로 이진분류를 다중분류로 바꾸어서 적용해보았다.\n",
    "그 결과 모든 값이 0.5176으로 동일하게 나왔으므로 모델링이 제대로 이루어지지 않았음을 알 수 있다.\n",
    "\n",
    "==> 원인은 2가지 중 하나로 판단된다.\n",
    "1. preds를 구성할 때 예측 확률값이 제대로 나오지 않았으므로 list가 제대로 구성되지 않았다.\n",
    "\n",
    "2. get_clf_eval 함수를 생성할 때 default값이 binary로 되어있어 이를 다중분류로 바꾸어 주는데 문제가 발생하였다.\n",
    "\n",
    "but! 랜덤 포레스트 모델이 뛰어난 성능을 보여주고 있으며 프로젝트 기간의 문제로 XGBoost는 여기까지를 한계로 둔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM(by 이태호)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Python39\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# LightGBM의 파이썬 패키지인 lightgbm에서 LGBMClassifier 임포트\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#데이터 로드\n",
    "farmdata = pd.read_csv('./data/dataset.csv', thousands=',')\n",
    "\n",
    "#결측치 제거\n",
    "farmdata.dropna(inplace=True)\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후 , fit( ) 과 transform( ) 으로 label 인코딩 수행. \n",
    "plants = ['딸기', '토마토', '파프리카']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(plants)\n",
    "labels = encoder.transform(plants)\n",
    "label_farmdata = farmdata.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "#데이터 분할\n",
    "data = label_farmdata[['외부 일사량', '내부온도', '내부습도', '내부CO2', '지습']].to_numpy()\n",
    "target = label_farmdata['품목명'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 앞서 XGBoost와 동일하게 n_estimators는 400 설정. \n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
    "                 eval_set=evals, verbose=False)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[ 756    1    0]\n",
      " [  16  653    4]\n",
      " [   0    2 1294]]\n",
      "정확도: 0.9916\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_importance( )를 이용하여 feature 중요도 시각화\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "plot_importance(lgbm_wrapper, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751232374183194\n",
      "0.9724896836313618\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#데이터 로드\n",
    "farmdata = pd.read_csv('./data/dataset.csv', thousands=',')\n",
    "\n",
    "#결측치 제거\n",
    "farmdata.dropna(inplace=True)\n",
    "\n",
    "#데이터 분할\n",
    "data = farmdata[['외부 일사량', '내부온도', '내부습도', '내부CO2', '지습']].to_numpy()\n",
    "target = farmdata['품목명'].to_numpy()\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "#훈련 데이터안에서 검증데이터 분할\n",
    "sub_input, val_input, sub_target, val_target = train_test_split(train_input,train_target, test_size=0.2, random_state=42)\n",
    "\n",
    "#모델 생성\n",
    "dt = DecisionTreeClassifier(random_state=156,min_samples_leaf=4,max_depth=7)\n",
    "\n",
    "#모델 학습\n",
    "dt.fit(sub_input, sub_target)\n",
    "\n",
    "print(dt.score(sub_input, sub_target))\n",
    "print(dt.score(val_input, val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.01795363, 0.01894855, 0.01994777, 0.02194047, 0.02493382]), 'score_time': array([0.00199318, 0.00099754, 0.00199461, 0.00199533, 0.00398898]), 'test_score': array([0.98074278, 0.97615773, 0.9738652 , 0.97799175, 0.97522936])}\n"
     ]
    }
   ],
   "source": [
    "# 교차검증\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(dt, train_input,train_target)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767973617017697\n"
     ]
    }
   ],
   "source": [
    "# 분류모델이기 때문에 KFold가 아닌 StratifiedKFold사용\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "scores = cross_validate(dt, train_input,train_target,cv=StratifiedKFold())\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증점수 : 0.9802\n",
      "최적의 매개변수 : {'min_impurity_decrease': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# 탐색할 매개변수의 값의 리스트를 딕셔너리로 만듬\n",
    "params = {'min_impurity_decrease':[0.0001,0.0002,0.0003,0.0004,0.0005]}\n",
    "\n",
    "# 모델 객체 생성\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=156,min_samples_leaf=4,max_depth=7), params, n_jobs=-1)\n",
    "\n",
    "# 모델 훈련(min_impurity_decrease5 *교차검증(5) = 25개의 모델을 훈련)\n",
    "gs.fit(train_input, train_target)\n",
    "\n",
    "# 점수가 가장 높은 하이퍼파라미터로 훈련한 모델이 저장\n",
    "dt=gs.best_estimator_\n",
    "\n",
    "print(f'검증점수 : {dt.score(train_input,train_target):0.4f}')\n",
    "print(f'최적의 매개변수 : {gs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97716429 0.97551329 0.97532985 0.97340404 0.97276214]\n"
     ]
    }
   ],
   "source": [
    "print(gs.cv_results_['mean_test_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
